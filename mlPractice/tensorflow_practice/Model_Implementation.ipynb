{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c89dc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cac6ccd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1858\n",
      "Epoch 2/50\n",
      "19/32 [================>.............] - ETA: 0s - loss: 1.4655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 02:50:52.188932: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 1.1494\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3408\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1212\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0632\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0476\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0433\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0423\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0420\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0419\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0419\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0419\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0419\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0419\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0419\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0419\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0419\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0419\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0419\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0419\n",
      "10/10 - 0s - loss: 0.0372 - 84ms/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 02:50:56.483845: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03722389414906502"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train = tf.random.normal(shape=(1000, ), dtype=tf.float32)\n",
    "y_train = 3*x_train + 1 + 0.2*tf.random.normal(shape=(1000, ), dtype=tf.float32)\n",
    "\n",
    "x_test = tf.random.normal(shape=(300, ), dtype=tf.float32)\n",
    "y_test = 3*x_test + 1 + 0.2*tf.random.normal(shape=(300, ), dtype=tf.float32)\n",
    "\n",
    "# sequential 방법\n",
    "model = tf.keras.models.Sequential([\n",
    "    # 레이어들을 의미\n",
    "    tf.keras.layers.Dense(units=1, input_shape=[1], activation='linear') # units -> 뉴련이 몇개 필요한가? activation -> 활성함수 지정\n",
    "])\n",
    "\n",
    "# 모델이 있을 때 로스라는 오브젝트를 달아주고 로스에다가 옵티마이저를 달아줘야한다.\n",
    "# 즉, 어떤로스를 쓸거냐, 어떤 옵티마이저를 쓸것인가\n",
    "model.compile(loss='mse', optimizer='SGD')\n",
    "\n",
    "# 이제 모델 학습\n",
    "model.fit(x_train, y_train, epochs=50)\n",
    "\n",
    "# 모델 테스트\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "849c38a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor(0.039628904, shape=(), dtype=float32)\n",
      "1 tf.Tensor(0.039628904, shape=(), dtype=float32)\n",
      "2 tf.Tensor(0.039628904, shape=(), dtype=float32)\n",
      "3 tf.Tensor(0.039628904, shape=(), dtype=float32)\n",
      "4 tf.Tensor(0.039628904, shape=(), dtype=float32)\n",
      "5 tf.Tensor(0.039628904, shape=(), dtype=float32)\n",
      "6 tf.Tensor(0.039628904, shape=(), dtype=float32)\n",
      "7 tf.Tensor(0.039628904, shape=(), dtype=float32)\n",
      "8 tf.Tensor(0.039628904, shape=(), dtype=float32)\n",
      "9 tf.Tensor(0.039628904, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# keras Model 클래스를 상속받는다.\n",
    "\n",
    "class LinearPredictor(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LinearPredictor, self).__init__()\n",
    "        \n",
    "        self.d1 = tf.keras.layers.Dense(units=1, activation='linear')\n",
    "    \n",
    "    # 순차적이지 않고 복잡한 뉴럴 네트워크일 경우 코드를 나눠서 맞춤 호출을 해줄 수 있음\n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        return x\n",
    "\n",
    "EPOCHS = 10\n",
    "LR = 0.01\n",
    "# init learning objects\n",
    "model = LinearPredictor()\n",
    "\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=LR)\n",
    "\n",
    "# learning\n",
    "for epoch in range(EPOCHS):\n",
    "    for x, y in zip(x_train, y_train):\n",
    "        x = tf.reshape(x, (1,1))\n",
    "        with tf.GradientTape() as tape:\n",
    "            h = model(x)\n",
    "            loss = loss_object(y, h)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    print(epoch, loss)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_for_everyone",
   "language": "python",
   "name": "ml_for_everyone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
