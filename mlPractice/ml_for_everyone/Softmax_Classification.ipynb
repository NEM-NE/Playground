{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feaa26b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab5c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "#convert into numpy and float format\n",
    "x_data = np.asarray(x_data, dtype=np.float32)\n",
    "y_data = np.asarray(y_data, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd665195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(8, 3)\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 3 #class의 개수입니다.\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7963b80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 23:30:03.776948: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-10 23:30:03.777445: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "<tf.Variable 'weight:0' shape=(4, 3) dtype=float32, numpy=\n",
      "array([[ 2.046651  , -0.61488664, -0.91315305],\n",
      "       [ 0.66364247, -0.68873894, -0.16364992],\n",
      "       [ 0.1197662 , -2.3775377 ,  0.40424803],\n",
      "       [-0.30651575,  0.6726224 , -0.7714349 ]], dtype=float32)> <tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([ 0.20364496, -1.5248002 , -0.91010517], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "#Weight and bias setting\n",
    "W = tf.Variable(tf.random.normal((4, nb_classes)), name='weight')\n",
    "b = tf.Variable(tf.random.normal((nb_classes,)), name='bias')\n",
    "variables = [W, b]\n",
    "\n",
    "print(W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f91e92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(features):\n",
    "    X = tf.matmul(features, W)\n",
    "    # softmax -> tf.nn.softmax(X + b)\n",
    "    # tf.reduce_sum(tf.exp(X+b), keepdims=True, axis=1) -> tf.exp(X+b)행렬의 가로축에 대해 합을 구한다 / keepdims=True -> 행렬의 차원을 유지한다\n",
    "    result = tf.divide(tf.exp(X+b), tf.reduce_sum(tf.exp(X+b), keepdims=True, axis=1))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5cdfedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-entropy\n",
    "def cost_fn(x, y):\n",
    "    logits = hypothesis(x)\n",
    "    cost = -tf.reduce_sum(y * tf.math.log(logits))\n",
    "    cost_mean = tf.reduce_mean(cost)\n",
    "    \n",
    "    return cost_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc4d206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(X, Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = cost_fn(X, Y)\n",
    "    \n",
    "    grads = tape.gradient(loss, [W, b])\n",
    "        \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82a5ddd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 0.007605\n",
      "Loss at epoch 100: 0.007358\n",
      "Loss at epoch 200: 0.007149\n",
      "Loss at epoch 300: 0.006974\n",
      "Loss at epoch 400: 0.006829\n",
      "Loss at epoch 500: 0.006709\n",
      "Loss at epoch 600: 0.006610\n",
      "Loss at epoch 700: 0.006528\n",
      "Loss at epoch 800: 0.006460\n",
      "Loss at epoch 900: 0.006405\n",
      "Loss at epoch 1000: 0.006358\n"
     ]
    }
   ],
   "source": [
    "def fit(X, Y, epochs=1000, verbose=100):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        optimizer.apply_gradients(zip(grad_fn(X, Y), [W, b]))\n",
    "        if(i==0) | ((i+1)%verbose == 0):\n",
    "             print('Loss at epoch %d: %f' %(i+1, cost_fn(X, Y).numpy()))\n",
    "fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0ba6eb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.3868584e-10 8.1802771e-04 9.9918205e-01]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([2], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "sample_data = [[2,1,3,2]] # answer_label [[0,0,1]]\n",
    "sample_data = np.asarray(sample_data, dtype=np.float32)\n",
    "\n",
    "a = hypothesis(sample_data)\n",
    "\n",
    "print(a)\n",
    "# tf.argmax -> 배열에서 가장 큰 값을 가진 인덱스 값 반환\n",
    "print(tf.argmax(a, 1)) #index: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d229ff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4.4076760e-25 1.5760945e-11 1.0000000e+00]\n",
      " [1.3868594e-10 8.1802835e-04 9.9918205e-01]\n",
      " [3.8729113e-34 6.3089828e-04 9.9936914e-01]\n",
      " [2.1036039e-25 9.9910325e-01 8.9674018e-04]\n",
      " [1.6629529e-03 9.9831790e-01 1.9161424e-05]\n",
      " [4.3122098e-04 9.9956876e-01 1.7706035e-14]\n",
      " [9.9810648e-01 1.8934758e-03 2.3753940e-15]\n",
      " [9.9999815e-01 1.8728310e-06 1.3302982e-22]], shape=(8, 3), dtype=float32)\n",
      "tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)\n",
      "tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "b = hypothesis(x_data)\n",
    "print(b)\n",
    "print(tf.argmax(b, 1))\n",
    "print(tf.argmax(y_data, 1)) # matches with y_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_for_everyone",
   "language": "python",
   "name": "ml_for_everyone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
